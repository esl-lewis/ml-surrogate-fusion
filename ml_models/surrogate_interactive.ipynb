{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9368a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import LeakyReLU  # this is already covered by import\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops.gen_sparse_ops import add_many_sparse_to_tensors_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d30e6",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c693cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = LeakyReLU(alpha=0.01)\n",
    "\n",
    "class CONFIG:\n",
    "    def __init__(self):\n",
    "        CONFIG.layer_1 = 12\n",
    "        CONFIG.activation_1 = leaky_relu\n",
    "        CONFIG.dropout = random.uniform(0.01, 0.80)\n",
    "        CONFIG.layer_2 = 10\n",
    "        CONFIG.activation_2 = \"relu\"\n",
    "        CONFIG.layer_3 = 7\n",
    "        CONFIG.optimizer = \"adam\"\n",
    "        CONFIG.loss = \"mae\"\n",
    "        CONFIG.metric = \"accuracy\"\n",
    "        CONFIG.epoch = 6\n",
    "        CONFIG.batch_size = 32\n",
    "\n",
    "\n",
    "config = CONFIG()\n",
    "\n",
    "\n",
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for our feature.\n",
    "    normalizer = preprocessing.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer\n",
    "\n",
    "\n",
    "def df_to_dataset(dataframe_X, dataframe_y, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe_X.copy()\n",
    "    labels = dataframe_y\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.ylim([0, 10])\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error [MAE]\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d0c20",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428b39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pulse_data = pd.read_csv(\"../JET_EFIT_magnetic/sampled_data.csv\")\n",
    "pulse_data = pulse_data.dropna(axis=0)\n",
    "\n",
    "y = pulse_data[\"FAXS\"]\n",
    "X = pulse_data.drop([\"FAXS\", \"FBND\", \"Time\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd09661",
   "metadata": {},
   "source": [
    "Check statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37600dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       std\n",
      "FAXS      0.120420  0.822241\n",
      "FBND      0.885580  0.914039\n",
      "Time     52.410838  8.295095\n",
      "BPME_13  -0.022851  0.245345\n",
      "BPME_17  -0.042618  0.205164\n",
      "FLME_19  -0.042366  0.117462\n",
      "BPME_9   -0.014746  0.195419\n",
      "FLME_17   0.008846  0.094223\n",
      "BPME_15  -0.035088  0.171885\n",
      "BPME_6    0.028976  0.403662\n",
      "FLME_14  -0.008491  0.080167\n",
      "BPME_1   -0.000458  0.012762\n",
      "FLME_12  -0.028657  0.166699\n",
      "BPME_4    0.002834  0.131903\n",
      "BPME_18  -0.040777  0.129938\n",
      "BPME_7    0.004489  0.088617\n",
      "FLME_13  -0.025188  0.086453\n",
      "BPME_3   -0.001670  0.035347\n",
      "FLME_9   -0.055496  0.193025\n",
      "FLME_10  -0.017101  0.053852\n",
      "FLME_38   0.026728  0.274919\n",
      "BPME_11  -0.032423  0.186289\n",
      "FLME_8   -0.007432  0.024769\n",
      "FLME_20   0.024980  0.110418\n",
      "FLME_11   0.000630  0.060033\n",
      "FLME_18  -0.024818  0.129153\n",
      "FLME_16  -0.028436  0.093404\n",
      "BPME_5   -0.001269  0.016878\n",
      "BPME_0   -0.000052  0.000416\n",
      "BPME_12  -0.024841  0.246943\n",
      "BPME_16  -0.046941  0.190630\n",
      "FLME_7   -0.026231  0.135816\n",
      "BPME_8    0.001054  0.136794\n",
      "FLME_15  -0.012824  0.135689\n",
      "BPME_10  -0.031525  0.227180\n",
      "BPME_2   -0.001594  0.019616\n",
      "FLME_37  -0.014461  0.165699\n",
      "BPME_14  -0.031131  0.165290\n"
     ]
    }
   ],
   "source": [
    "print(pulse_data.describe().transpose()[['mean', 'std']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5c3224",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeed2d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 train examples\n",
      "60 validation examples\n",
      "74 test examples\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "             mean       std\n",
      "BPME_13 -0.025093  0.262644\n",
      "BPME_17 -0.049616  0.228944\n",
      "FLME_19 -0.046424  0.118706\n",
      "BPME_9  -0.024260  0.229347\n",
      "FLME_17  0.006926  0.092070\n",
      "BPME_15 -0.045869  0.166465\n",
      "BPME_6   0.020864  0.357395\n",
      "FLME_14 -0.008120  0.079468\n",
      "BPME_1  -0.000734  0.010042\n",
      "FLME_12 -0.028860  0.163478\n",
      "BPME_4   0.008301  0.159686\n",
      "BPME_18 -0.043399  0.149357\n",
      "BPME_7   0.007439  0.092452\n",
      "FLME_13 -0.019919  0.086224\n",
      "BPME_3  -0.000501  0.028762\n",
      "FLME_9  -0.063998  0.199741\n",
      "FLME_10 -0.016106  0.053617\n",
      "FLME_38  0.017232  0.271997\n",
      "BPME_11 -0.044247  0.225500\n",
      "FLME_8  -0.008135  0.025003\n",
      "FLME_20  0.023486  0.113627\n",
      "FLME_11 -0.000674  0.061553\n",
      "FLME_18 -0.017184  0.126390\n",
      "FLME_16 -0.024307  0.096293\n",
      "BPME_5  -0.000351  0.019276\n",
      "BPME_0  -0.000056  0.000427\n",
      "BPME_12 -0.012679  0.213829\n",
      "BPME_16 -0.054119  0.215216\n",
      "FLME_7  -0.022734  0.130048\n",
      "BPME_8   0.001445  0.129511\n",
      "FLME_15 -0.012250  0.134378\n",
      "BPME_10 -0.032670  0.251006\n",
      "BPME_2  -0.001274  0.017358\n",
      "FLME_37 -0.016418  0.165251\n",
      "BPME_14 -0.023757  0.160493\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=24\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=24\n",
    ")\n",
    "\n",
    "\n",
    "print(len(X_train), \"train examples\")\n",
    "print(len(X_val), \"validation examples\")\n",
    "print(len(X_test), \"test examples\")\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(X))\n",
    "\n",
    "print(X_train.describe().transpose()[['mean', 'std']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d153f3",
   "metadata": {},
   "source": [
    "Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3521e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                1440      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 2,470\n",
      "Trainable params: 2,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(40, input_dim=35),\n",
    "        tf.keras.layers.Dense(20, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"mae\", metrics=\"mape\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa098f0",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf350016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6939 - mape: 111.3654 - val_loss: 0.7050 - val_mape: 103.9071\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6925 - mape: 110.7993 - val_loss: 0.7044 - val_mape: 103.7090\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6910 - mape: 110.2546 - val_loss: 0.7038 - val_mape: 103.6200\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6897 - mape: 109.8143 - val_loss: 0.7032 - val_mape: 103.5994\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6883 - mape: 109.3641 - val_loss: 0.7027 - val_mape: 103.6136\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6870 - mape: 108.9282 - val_loss: 0.7023 - val_mape: 103.6501\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6856 - mape: 108.5067 - val_loss: 0.7020 - val_mape: 103.6979\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6843 - mape: 108.0949 - val_loss: 0.7016 - val_mape: 103.7469\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6831 - mape: 107.6990 - val_loss: 0.7011 - val_mape: 103.7893\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6818 - mape: 107.3070 - val_loss: 0.7007 - val_mape: 103.8325\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6806 - mape: 106.9224 - val_loss: 0.7003 - val_mape: 103.8733\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6795 - mape: 106.5723 - val_loss: 0.6999 - val_mape: 104.0591\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6783 - mape: 106.2604 - val_loss: 0.6996 - val_mape: 104.2747\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6772 - mape: 105.9631 - val_loss: 0.6993 - val_mape: 104.4787\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6762 - mape: 105.6781 - val_loss: 0.6991 - val_mape: 104.6741\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6751 - mape: 105.4091 - val_loss: 0.6989 - val_mape: 104.8629\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6741 - mape: 105.1573 - val_loss: 0.6987 - val_mape: 105.0683\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6731 - mape: 104.9205 - val_loss: 0.6986 - val_mape: 105.2813\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6722 - mape: 104.6636 - val_loss: 0.6985 - val_mape: 105.4801\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6712 - mape: 104.4013 - val_loss: 0.6985 - val_mape: 105.6683\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6702 - mape: 104.1232 - val_loss: 0.6985 - val_mape: 105.8362\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6693 - mape: 103.8209 - val_loss: 0.6986 - val_mape: 106.0127\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6684 - mape: 103.5249 - val_loss: 0.6987 - val_mape: 106.2663\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6675 - mape: 103.2733 - val_loss: 0.6989 - val_mape: 106.5331\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6666 - mape: 102.9974 - val_loss: 0.6991 - val_mape: 106.7832\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6657 - mape: 102.6921 - val_loss: 0.6994 - val_mape: 107.0134\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6648 - mape: 102.4151 - val_loss: 0.6996 - val_mape: 107.2224\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6639 - mape: 102.1346 - val_loss: 0.6999 - val_mape: 107.4197\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6630 - mape: 101.8360 - val_loss: 0.7002 - val_mape: 107.6142\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6622 - mape: 101.5191 - val_loss: 0.7005 - val_mape: 107.8059\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6613 - mape: 101.1985 - val_loss: 0.7008 - val_mape: 107.9877\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6604 - mape: 100.8766 - val_loss: 0.7011 - val_mape: 108.1911\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6595 - mape: 100.5700 - val_loss: 0.7015 - val_mape: 108.3798\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6587 - mape: 100.2729 - val_loss: 0.7018 - val_mape: 108.5556\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6578 - mape: 99.9658 - val_loss: 0.7021 - val_mape: 108.7031\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6569 - mape: 99.6595 - val_loss: 0.7024 - val_mape: 108.8267\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6561 - mape: 99.3719 - val_loss: 0.7028 - val_mape: 108.9488\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6552 - mape: 99.0388 - val_loss: 0.7032 - val_mape: 109.1038\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6543 - mape: 98.6992 - val_loss: 0.7036 - val_mape: 109.2930\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6534 - mape: 98.3593 - val_loss: 0.7040 - val_mape: 109.4850\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6525 - mape: 98.0627 - val_loss: 0.7044 - val_mape: 109.6694\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6517 - mape: 97.7738 - val_loss: 0.7048 - val_mape: 109.8684\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6508 - mape: 97.5134 - val_loss: 0.7053 - val_mape: 110.0761\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6500 - mape: 97.2848 - val_loss: 0.7058 - val_mape: 110.3064\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6491 - mape: 97.0720 - val_loss: 0.7063 - val_mape: 110.5458\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6482 - mape: 96.8679 - val_loss: 0.7068 - val_mape: 110.8013\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6473 - mape: 96.6626 - val_loss: 0.7074 - val_mape: 111.0688\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6464 - mape: 96.4464 - val_loss: 0.7079 - val_mape: 111.3388\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6455 - mape: 96.2173 - val_loss: 0.7085 - val_mape: 111.6222\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6446 - mape: 95.9797 - val_loss: 0.7091 - val_mape: 111.9417\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6436 - mape: 95.7413 - val_loss: 0.7097 - val_mape: 112.2925\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6427 - mape: 95.5269 - val_loss: 0.7102 - val_mape: 112.6527\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6418 - mape: 95.3312 - val_loss: 0.7108 - val_mape: 113.0303\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6408 - mape: 95.1408 - val_loss: 0.7114 - val_mape: 113.4241\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6399 - mape: 94.9539 - val_loss: 0.7119 - val_mape: 113.8059\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6390 - mape: 94.7663 - val_loss: 0.7125 - val_mape: 114.1726\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6380 - mape: 94.5670 - val_loss: 0.7131 - val_mape: 114.5096\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6370 - mape: 94.3559 - val_loss: 0.7136 - val_mape: 114.8416\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6361 - mape: 94.1676 - val_loss: 0.7142 - val_mape: 115.2012\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6351 - mape: 94.0049 - val_loss: 0.7147 - val_mape: 115.5875\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6341 - mape: 93.8679 - val_loss: 0.7153 - val_mape: 116.0104\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6332 - mape: 93.7393 - val_loss: 0.7158 - val_mape: 116.4039\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6322 - mape: 93.5894 - val_loss: 0.7163 - val_mape: 116.7575\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6312 - mape: 93.4143 - val_loss: 0.7168 - val_mape: 117.1117\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6303 - mape: 93.2308 - val_loss: 0.7174 - val_mape: 117.4358\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6293 - mape: 93.0474 - val_loss: 0.7179 - val_mape: 117.7283\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6283 - mape: 92.8386 - val_loss: 0.7184 - val_mape: 117.9930\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6273 - mape: 92.6242 - val_loss: 0.7189 - val_mape: 118.2624\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6263 - mape: 92.4391 - val_loss: 0.7194 - val_mape: 118.5656\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6253 - mape: 92.2729 - val_loss: 0.7198 - val_mape: 118.8679\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6243 - mape: 92.1044 - val_loss: 0.7203 - val_mape: 119.1493\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6233 - mape: 91.9230 - val_loss: 0.7209 - val_mape: 119.4290\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6223 - mape: 91.7511 - val_loss: 0.7215 - val_mape: 119.6858\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6213 - mape: 91.6199 - val_loss: 0.7220 - val_mape: 119.9470\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6203 - mape: 91.5048 - val_loss: 0.7225 - val_mape: 120.2119\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6193 - mape: 91.4101 - val_loss: 0.7230 - val_mape: 120.4915\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6183 - mape: 91.3464 - val_loss: 0.7234 - val_mape: 120.7336\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6173 - mape: 91.2822 - val_loss: 0.7239 - val_mape: 120.9313\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6164 - mape: 91.2142 - val_loss: 0.7244 - val_mape: 121.0734\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6154 - mape: 91.1318 - val_loss: 0.7249 - val_mape: 121.1806\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6144 - mape: 91.0564 - val_loss: 0.7253 - val_mape: 121.2663\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6134 - mape: 90.9783 - val_loss: 0.7256 - val_mape: 121.3220\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6125 - mape: 90.9022 - val_loss: 0.7259 - val_mape: 121.3103\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6115 - mape: 90.8353 - val_loss: 0.7262 - val_mape: 121.2934\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6106 - mape: 90.7671 - val_loss: 0.7266 - val_mape: 121.3460\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6097 - mape: 90.6506 - val_loss: 0.7270 - val_mape: 121.4233\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6087 - mape: 90.5302 - val_loss: 0.7273 - val_mape: 121.4642\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6078 - mape: 90.4227 - val_loss: 0.7276 - val_mape: 121.4828\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6069 - mape: 90.2977 - val_loss: 0.7278 - val_mape: 121.4674\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6060 - mape: 90.1740 - val_loss: 0.7281 - val_mape: 121.4120\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6051 - mape: 90.0290 - val_loss: 0.7284 - val_mape: 121.3053\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6041 - mape: 89.8780 - val_loss: 0.7286 - val_mape: 121.1244\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6033 - mape: 89.7433 - val_loss: 0.7288 - val_mape: 120.9000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6023 - mape: 89.6158 - val_loss: 0.7288 - val_mape: 120.6372\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6015 - mape: 89.5582 - val_loss: 0.7289 - val_mape: 120.4099\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6006 - mape: 89.4609 - val_loss: 0.7291 - val_mape: 120.1658\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5997 - mape: 89.3042 - val_loss: 0.7294 - val_mape: 119.9280\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5988 - mape: 89.1052 - val_loss: 0.7296 - val_mape: 119.7326\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5980 - mape: 88.9198 - val_loss: 0.7298 - val_mape: 119.4745\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5972 - mape: 88.7676 - val_loss: 0.7298 - val_mape: 119.1508\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "# Not worried about memory or local minima\n",
    "batchSize = len(X_train)\n",
    "\n",
    "# Train on data\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=batchSize,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d4213",
   "metadata": {},
   "source": [
    "Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56bde1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.7162 - mae: 0.7162\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'], label='mae')\n",
    "plt.plot(history.history['val_mae'], label = 'val_mae')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mae')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "val_loss, val_acc = model.evaluate(X_val,  y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e01bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
